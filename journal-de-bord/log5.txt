Mardi 22 Juillet
~3h

Refonte d'une liste de modèles a tester (on prends les modèles qui peuvent aussi prendre des images en input et on exclut ceux qui ne prennent que du texte).

-gemma3:4b (existe aussi en 12b et 27b mais pas sur que le raspberry survive (le 12b peut etre avec le AI hat)
-llava:7b
-minicpm-v:8b
-llama3.2-vision:11b
-llava-llama3:8b
-moondream:1.8b
-granite3.2-vision:2b
-bakllava:7b
-llava-phi3:3.8b

Si aucun des précedents n'est convainquant :
	-mistral-small3.2:24b
	
On commence a créer ce qui concerne les testes. On a fait une selection de plusieurs images qui pourrais eventuellement rappeler le contexte qu'il pourrait rencontrer lors d'une réelle utilisation. On crée aussi le prompt system (prompt permettant d'alligner l'IA sur nos attentes).

--prompt system
"You are a boat equipped with a GPS, a camera, and numerous sensors. Your mission is to analyze the provided image along with the data collected from your various sensors. Based on this information, you must determine the best course of action, taking into account any obstacles. Your objective is to respond appropriately and provide the most effective way to navigate the situation safely and efficiently."

--prompt test
"
leftEngine = 2000RPM
rightEngine = 2000RPM

FrontLiDAR:
Angle: 0.00 Distance: 1200 Quality: 15
Angle: 1.00 Distance: 1195 Quality: 13
Angle: 2.00 Distance: 1180 Quality: 10

GPSposition:
now = $GPGGA,123519,4807.038,N,01131.000,E,1,08,0.9,545.4,M,46.9,M,,*47
target = 4916.45,N,12311.12,W
"

on a créer un projet git avec un programme permettant de test toutes les images et enregistrer les resultats dans un nouveau fichier json. Demain on finira le code pour pouvoir prendre des mesures de temps d'execution, et nous commencerons les tests.

repo github : https://github.com/Humira40mg/Projet-Tutoree

